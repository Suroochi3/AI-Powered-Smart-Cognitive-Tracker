# ğŸ§  AI Powered Smart Cognitive Tracker

This repository represents the final integration point of a multimodal AI system designed to detect early signs of mental health issues in adolescents. It brings together multiple independently trained AI models and fuses select components to deliver a comprehensive cognitive and emotional risk analysis.

---

## ğŸ” What This Repository Contains

This is the **main fusion repository** of the project. It includes:

- âœ… **Fusion between Vision Transformer (ViT)** and **XGBoost** models
- âœ… References to 4 **individually trained models** stored in separate GitHub repositories
- âœ… Explanation of how the fusion is performed using **output extracts** from those model repositories
- âœ… Clarification that **BERT** and **Wav2Vec** are used as **standalone predictors** outside the fusion pipeline

---

## ğŸ”— Linked Repositories (Individual Models)

Each of the following models is hosted in a separate GitHub repository:

| Model | Task | Repo |
|-------|------|------|
| ğŸ§  BERT | Text emotion detection (standalone) | [BERT Text Emotion Analyzer](https://github.com/Suroochi3/bert-text-emotion-analyzer) |
| ğŸ­ ViT | Facial expression recognition (used in fusion) | [ViT Facial Expression Analyzer](https://github.com/Suroochi3/vit-facial-expression-analyzer) |
| ğŸ”Š Wav2Vec 2.0 | Voice emotion detection (standalone) | [Wav2Vec Voice Emotion Analyzer](https://github.com/Suroochi3/wav2vec-voice-emotion-analyzer) |
| ğŸ“Š XGBoost | Academic & health data analysis (used in fusion) | [XGBoost Mental Health Predictor](https://github.com/Suroochi3/xgboost-mental-health-predictor) |

---

## ğŸ”— Fusion Logic (ViT + XGBoost Only)

In this repository, we perform **partial multimodal fusion** between the **ViT** and **XGBoost** models:

- âœ… **ViT** provides emotion predictions from facial expressions
- âœ… **XGBoost** provides risk predictions based on academic and health records
- These predictions are then **fused** into a joint decision using simple concatenation or voting mechanisms.

The output predictions used for fusion are **not generated here**, but are instead:
> ğŸ“ **Pre-extracted and available inside their respective repositories (ViT and XGBoost)**

---

## ğŸš« Not Fused in This Repository

- âœ… **BERT** and **Wav2Vec** models are **standalone** components of the full system. They are trained independently and used separately from this fusion pipeline.
- Their individual outputs contribute to the overall system evaluation but are **not integrated into the fusion model here**.

---

## ğŸ“‚ Files in This Repo

- `MULTI_MODEL_FUSION.ipynb`  
  â†’ Main notebook that loads output predictions from ViT & XGBoost and performs fusion.

- `README.md`  
  â†’ This file.

- `requirements.txt` *(optional)*  
  â†’ Add if you want to auto-install libraries.

---

## ğŸš€ Run in Google Colab

[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Suroochi3/AI-Powered-Smart-Cognitive-tracker/blob/main/MULTI_MODEL_FUSION.ipynb)

---



## ğŸ§  System Architecture Summary

Text (BERT)       â†’ Standalone
Voice (Wav2Vec)   â†’ Standalone

Image (ViT)  â†˜ 
              â†’ Partial Fusion â†’ Final Risk Score
Tabular (XGB) â†—

## ğŸ“¦ Requirements

```bash
pip install pandas scikit-learn xgboost torch torchvision timm
