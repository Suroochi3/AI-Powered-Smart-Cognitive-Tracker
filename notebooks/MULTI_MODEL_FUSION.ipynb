{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Load All Extracted Feature Arrays**"
      ],
      "metadata": {
        "id": "x66Y6wIhR40G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "65-U7t7iR2vi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5179a478-2078-4827-d71e-5231292105d5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT shape: (5802, 768)\n",
            "ViT Train shape: (28709, 768)\n",
            "XGBoost shape: (27901, 17)\n",
            "Wav2Vec shape: (1148, 768)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Load your features\n",
        "bert_features = np.load(\"/content/bert_features_fixed.npy\")\n",
        "vit_train_features = np.load(\"/content/vit_train_features (1).npy\")  # shape (28709, 768)\n",
        "xgb_features = np.load(\"/content/xgboost_features.npy\")\n",
        "wav_features = np.load(\"/content/wav2vec_features.npy\")\n",
        "\n",
        "print(\"BERT shape:\", bert_features.shape)\n",
        "print(\"ViT Train shape:\", vit_train_features.shape)\n",
        "print(\"XGBoost shape:\", xgb_features.shape)\n",
        "print(\"Wav2Vec shape:\", wav_features.shape)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "bert_labels = np.load(\"/content/bert_labels.npy\")\n",
        "vit_train_labels = np.load(\"/content/vit_train_labels.npy\")\n",
        "vit_test_labels = np.load(\"/content/vit_test_labels.npy\")\n",
        "wav2vec_labels = np.load(\"/content/wav2vec_labels.npy\")\n",
        "xgboost_labels = np.load(\"/content/xgboost_labels.npy\")\n",
        "\n",
        "print(\"bert_labels:\", bert_labels.shape)\n",
        "print(\"vit_train_labels:\", vit_train_labels.shape)\n",
        "print(\"vit_test_labels:\", vit_test_labels.shape)\n",
        "print(\"wav2vec_labels:\", wav2vec_labels.shape)\n",
        "print(\"xgboost_labels:\", xgboost_labels.shape)\n"
      ],
      "metadata": {
        "id": "dr9ygWSrBLAR",
        "outputId": "ab9dbb40-50a6-461e-d7fb-135708167ae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bert_labels: (53043,)\n",
            "vit_train_labels: (28709,)\n",
            "vit_test_labels: (14356,)\n",
            "wav2vec_labels: (1148,)\n",
            "xgboost_labels: (27901,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ViT + XGBoost Fusion**"
      ],
      "metadata": {
        "id": "sjMWCV6VCUnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# 1. Load Features and Labels\n",
        "vit = np.load(\"/content/vit_train_features (1).npy\")[:27901]\n",
        "xgb = np.load(\"/content/xgboost_features.npy\")[:27901]\n",
        "labels = np.load(\"/content/xgboost_labels.npy\")[:27901]\n",
        "\n",
        "print(\"Loaded shapes:\")\n",
        "print(\"ViT:\", vit.shape)\n",
        "print(\"XGBoost:\", xgb.shape)\n",
        "print(\"Labels:\", labels.shape)\n",
        "\n",
        "# 2. Normalize features\n",
        "scaler_vit = StandardScaler()\n",
        "scaler_xgb = StandardScaler()\n",
        "\n",
        "vit_scaled = scaler_vit.fit_transform(vit)\n",
        "xgb_scaled = scaler_xgb.fit_transform(xgb)\n",
        "\n",
        "# 3. Fuse features\n",
        "fused_features = np.concatenate((vit_scaled, xgb_scaled), axis=1)\n",
        "print(\"Fused feature shape:\", fused_features.shape)\n",
        "\n",
        "# 4. Convert to PyTorch tensors\n",
        "features_tensor = torch.tensor(fused_features, dtype=torch.float32)\n",
        "labels_tensor = torch.tensor(labels, dtype=torch.long)\n",
        "\n",
        "# 5. Dataset & Dataloader\n",
        "class FusionDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.features = features\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.features.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.labels[idx]\n",
        "\n",
        "dataset = FusionDataset(features_tensor, labels_tensor)\n",
        "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "# 6. Define Classifier\n",
        "class FusionClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 512)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc3(x)\n",
        "\n",
        "# 7. Setup for training\n",
        "input_dim = fused_features.shape[1]\n",
        "num_classes = len(np.unique(labels))\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = FusionClassifier(input_dim, num_classes).to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "num_epochs = 10\n",
        "\n",
        "# 8. Training Loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_correct = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch_features, batch_labels in dataloader:\n",
        "        batch_features = batch_features.to(device)\n",
        "        batch_labels = batch_labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(batch_features)\n",
        "        loss = criterion(outputs, batch_labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item() * batch_features.size(0)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        total_correct += (preds == batch_labels).sum().item()\n",
        "        total_samples += batch_features.size(0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} — Loss: {total_loss/total_samples:.4f}, Accuracy: {total_correct/total_samples:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QD-a6hYY_xw5",
        "outputId": "30d5f8ad-f5f1-438a-989f-0e6d557b02c8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded shapes:\n",
            "ViT: (27901, 768)\n",
            "XGBoost: (27901, 17)\n",
            "Labels: (27901,)\n",
            "Fused feature shape: (27901, 785)\n",
            "Epoch 1/10 — Loss: 0.4619, Accuracy: 0.7803\n",
            "Epoch 2/10 — Loss: 0.3799, Accuracy: 0.8352\n",
            "Epoch 3/10 — Loss: 0.3627, Accuracy: 0.8465\n",
            "Epoch 4/10 — Loss: 0.3533, Accuracy: 0.8486\n",
            "Epoch 5/10 — Loss: 0.3477, Accuracy: 0.8507\n",
            "Epoch 6/10 — Loss: 0.3350, Accuracy: 0.8551\n",
            "Epoch 7/10 — Loss: 0.3280, Accuracy: 0.8588\n",
            "Epoch 8/10 — Loss: 0.3249, Accuracy: 0.8605\n",
            "Epoch 9/10 — Loss: 0.3114, Accuracy: 0.8625\n",
            "Epoch 10/10 — Loss: 0.3060, Accuracy: 0.8643\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP-BY-STEP CLASSIFIER TRAINING FOR BERT AND WAV2VEC FEATURES\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# DEVICE SETUP\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# LOAD FEATURES & LABELS\n",
        "bert_features = np.load(\"/content/bert_features_fixed.npy\")\n",
        "bert_labels = np.load(\"/content/bert_labels.npy\")\n",
        "\n",
        "wav_features = np.load(\"/content/wav2vec_features.npy\")\n",
        "wav_labels = np.load(\"/content/wav2vec_labels.npy\")\n",
        "\n",
        "print(\"Shapes:\")\n",
        "print(\"BERT:\", bert_features.shape, bert_labels.shape)\n",
        "print(\"Wav2Vec:\", wav_features.shape, wav_labels.shape)\n",
        "\n",
        "# STANDARD SCALING\n",
        "scaler_bert = StandardScaler()\n",
        "scaler_wav = StandardScaler()\n",
        "bert_scaled = scaler_bert.fit_transform(bert_features)\n",
        "wav_scaled = scaler_wav.fit_transform(wav_features)\n",
        "\n",
        "# CONVERT TO TENSORS\n",
        "bert_X = torch.tensor(bert_scaled, dtype=torch.float32)\n",
        "bert_y = torch.tensor(bert_labels, dtype=torch.long)\n",
        "\n",
        "wav_X = torch.tensor(wav_scaled, dtype=torch.float32)\n",
        "wav_y = torch.tensor(wav_labels, dtype=torch.long)\n",
        "\n",
        "# DATASET CLASS\n",
        "class SimpleDataset(Dataset):\n",
        "    def __init__(self, features, labels):\n",
        "        self.X = features\n",
        "        self.y = labels\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]\n",
        "\n",
        "# MODEL\n",
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_dim, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 256)\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc2 = nn.Linear(256, num_classes)\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        return self.fc2(x)\n",
        "\n",
        "# TRAINING FUNCTION\n",
        "def train_model(X, y, name):\n",
        "    dataset = SimpleDataset(X, y)\n",
        "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "\n",
        "    num_classes = len(torch.unique(y))\n",
        "    model = SimpleClassifier(X.shape[1], num_classes).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    print(f\"\\nTraining {name} classifier:\")\n",
        "    for epoch in range(10):\n",
        "        model.train()\n",
        "        total_loss, correct, total = 0, 0, 0\n",
        "        for features, labels in dataloader:\n",
        "            features, labels = features.to(device), labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(features)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item() * features.size(0)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            correct += (preds == labels).sum().item()\n",
        "            total += features.size(0)\n",
        "\n",
        "        acc = correct / total\n",
        "        print(f\"Epoch {epoch+1}/10 - Loss: {total_loss/total:.4f}, Accuracy: {acc:.4f}\")\n",
        "\n",
        "# RUN TRAINING\n",
        "train_model(bert_X, bert_y, \"BERT\")\n",
        "train_model(wav_X, wav_y, \"Wav2Vec\")\n"
      ],
      "metadata": {
        "id": "Xf-eNL2CEvbt",
        "outputId": "f70aaefc-2b0f-4675-c8c2-f1496210a7f8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shapes:\n",
            "BERT: (5802, 768) (53043,)\n",
            "Wav2Vec: (1148, 768) (1148,)\n",
            "\n",
            "Training BERT classifier:\n",
            "Epoch 1/10 - Loss: 0.5560, Accuracy: 0.8626\n",
            "Epoch 2/10 - Loss: 0.2693, Accuracy: 0.8912\n",
            "Epoch 3/10 - Loss: 0.2236, Accuracy: 0.9062\n",
            "Epoch 4/10 - Loss: 0.1908, Accuracy: 0.9221\n",
            "Epoch 5/10 - Loss: 0.1649, Accuracy: 0.9354\n",
            "Epoch 6/10 - Loss: 0.1484, Accuracy: 0.9404\n",
            "Epoch 7/10 - Loss: 0.1322, Accuracy: 0.9511\n",
            "Epoch 8/10 - Loss: 0.1157, Accuracy: 0.9583\n",
            "Epoch 9/10 - Loss: 0.1050, Accuracy: 0.9616\n",
            "Epoch 10/10 - Loss: 0.0909, Accuracy: 0.9657\n",
            "\n",
            "Training Wav2Vec classifier:\n",
            "Epoch 1/10 - Loss: 1.6760, Accuracy: 0.3685\n",
            "Epoch 2/10 - Loss: 1.1485, Accuracy: 0.6002\n",
            "Epoch 3/10 - Loss: 0.8855, Accuracy: 0.6943\n",
            "Epoch 4/10 - Loss: 0.7406, Accuracy: 0.7448\n",
            "Epoch 5/10 - Loss: 0.6182, Accuracy: 0.7944\n",
            "Epoch 6/10 - Loss: 0.5109, Accuracy: 0.8537\n",
            "Epoch 7/10 - Loss: 0.4393, Accuracy: 0.8720\n",
            "Epoch 8/10 - Loss: 0.3570, Accuracy: 0.9007\n",
            "Epoch 9/10 - Loss: 0.3228, Accuracy: 0.9103\n",
            "Epoch 10/10 - Loss: 0.2691, Accuracy: 0.9347\n"
          ]
        }
      ]
    }
  ]
}